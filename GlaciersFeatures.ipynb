{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import queue\n",
    "import png\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['image.cmap'] = 'bone'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input: DEM, ice thickness, ELA mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demPath = 'data/maps/aiguestortes/dem.png'\n",
    "icePath = 'data/maps/aiguestortes/ice.png'\n",
    "elaPath = 'data/maps/aiguestortes/ela.png'\n",
    "\n",
    "# IMPORTANT: cell sizes must match those in simulation\n",
    "dx = 20\n",
    "dy = 20\n",
    "\n",
    "outPath = 'data/maps/aiguestortes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DEM\n",
    "Bed = cv2.imread(demPath, cv2.IMREAD_ANYDEPTH).astype(np.double)*0.1\n",
    "nx, ny = Bed.shape\n",
    "\n",
    "img = cv2.imread(icePath).astype(np.double)\n",
    "Ice = img[:,:,0]/255 + img[:,:,1] + img[:,:,2]*255;\n",
    "Ice = np.flipud(Ice)\n",
    "\n",
    "elaMap = np.flipud(cv2.imread(elaPath).astype(np.int)[:,:,0])\n",
    "\n",
    "Surf = Bed + Ice\n",
    "mapShape = Bed.shape\n",
    "\n",
    "ice_above_ELA = np.logical_and(Ice > 0, elaMap > 0)\n",
    "ice_below_ELA = np.logical_and(Ice > 0, elaMap == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(Bed, cmap='terrain')\n",
    "ax = fig.add_subplot(132)\n",
    "ax.imshow(np.sqrt(Ice))\n",
    "ax = fig.add_subplot(133)\n",
    "ax.imshow(ice_above_ELA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxy  = np.sqrt(dx*dx+dy*dy)\n",
    "isq2 = 1.0/np.sqrt(2.0)\n",
    "CELL_NEIGHS = [      (-1,-1), (-1,0),       (-1,1), (0,-1), (0,1),       (1,-1), (1,0),       (1,1)]\n",
    "DIST_NEIGHS = [          dxy,     dx,          dxy,     dy,    dy,          dxy,    dx,         dxy]\n",
    "DIR_NEIGHS  = [(-isq2,-isq2), (-1,0), (-isq2,isq2), (0,-1), (0,1), (isq2,-isq2), (1,0), (isq2,isq2)]\n",
    "\n",
    "CELL_NEIGHS_4 = [(-1,0), (0,-1), (0,1), (1,0)]\n",
    "DIST_NEIGHS_4 = [dy, dx, dx, dy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di   = np.arange(nx)\n",
    "dj   = np.arange(ny)\n",
    "dip  = np.hstack([np.arange(1,nx), nx-1])\n",
    "dim  = np.hstack([0, np.arange(0, nx-1)])\n",
    "djp  = np.hstack([np.arange(1,ny), ny-1])\n",
    "djm  = np.hstack([0, np.arange(0, ny-1)])\n",
    "\n",
    "cellIdx = (np.meshgrid(di,dj)[1], np.meshgrid(di,dj)[0])\n",
    "\n",
    "neighs8idx = [\n",
    "    (np.meshgrid(dim,djm)[1], np.meshgrid(dim,djm)[0]),\n",
    "    (np.meshgrid(dim,dj)[1], np.meshgrid(dim,dj)[0]),\n",
    "    (np.meshgrid(dim,djp)[1], np.meshgrid(dim,djp)[0]),\n",
    "    (np.meshgrid(di,djm)[1], np.meshgrid(di,djm)[0]),\n",
    "    (np.meshgrid(di,djp)[1], np.meshgrid(di,djp)[0]),\n",
    "    (np.meshgrid(dip,djm)[1], np.meshgrid(dip,djm)[0]),\n",
    "    (np.meshgrid(dip,dj)[1], np.meshgrid(dip,dj)[0]),\n",
    "    (np.meshgrid(dip,djp)[1], np.meshgrid(dip,djp)[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(field):\n",
    "    grad_x = (field[dip,:] - field[dim,:])/(2*dx)\n",
    "    grad_y = (field[:,djp] - field[:,djm])/(2*dy)\n",
    "    return grad_x, grad_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineSign(A, B, X):\n",
    "    return np.sign((B[0] - A[0])*(X[1] - A[1]) - (B[1] - A[1])*(X[0] - A[0]))\n",
    "\n",
    "def linearstep(x, mi, mx):\n",
    "    return (lambda t: np.where(t < 0, 0, np.where(t <= 1, t, 1)))( (x-mi)/(mx-mi) )\n",
    "\n",
    "def smoothstep(x, mi, mx): \n",
    "    return (lambda t: np.where(t < 0, 0, np.where(t <= 1, 3*t**2-2*t**3, 1)))( (x-mi)/(mx-mi) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeFieldAsRGB(values):\n",
    "    c = (np.maximum(0, (values/65536.0)) * (256.0 * 256.0 * 256.0 - 1.0)).astype(int);\n",
    "    cr = np.bitwise_and(np.right_shift(c, 16), 255).astype(np.uint8);\n",
    "    cg = np.bitwise_and(np.right_shift(c, 8),  255).astype(np.uint8);\n",
    "    cb = np.bitwise_and(c, 255).astype(np.uint8);\n",
    "    c = np.dstack([cb, cg, cr])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Glacier properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grad_B_x, Grad_B_y = gradient(Bed)\n",
    "Grad_S_x, Grad_S_y = gradient(Surf)\n",
    "\n",
    "Gradient = np.sqrt(Grad_S_x*Grad_S_x + Grad_S_y*Grad_S_y)\n",
    "\n",
    "FlowDir = np.dstack([-Grad_S_x, -Grad_S_y])\n",
    "FlowDir[Gradient > 0] = FlowDir[Gradient > 0]/Gradient[Gradient > 0, np.newaxis]\n",
    "\n",
    "SurfaceNormal    = np.dstack([-Grad_S_x, -Grad_S_y, np.ones(mapShape)])\n",
    "SurfaceNormalMag = np.linalg.norm(SurfaceNormal, axis=2)\n",
    "SurfaceNormal[SurfaceNormalMag > 0] = SurfaceNormal[SurfaceNormalMag > 0]/SurfaceNormalMag[SurfaceNormalMag > 0, np.newaxis]\n",
    "\n",
    "IceSlopeAngle = np.zeros(mapShape) \n",
    "IceSlopeAngle[SurfaceNormalMag > 0] = 0.5*np.pi - np.arccos(Gradient[SurfaceNormalMag > 0]\n",
    "                                                            /SurfaceNormalMag[SurfaceNormalMag > 0])\n",
    "\n",
    "Tau = 910*9.81*Ice*Gradient\n",
    "\n",
    "IceFlowing = Tau > 50000  # we will consider 50 kPa the stress regime when ice begins to flow plastically\n",
    "\n",
    "Gamma_d = 7.26e-5\n",
    "Gamma_s = 3.27\n",
    "Uslide  = Gamma_s * pow(Ice, 2.0) * pow(Gradient, 2.0)\n",
    "Udeform = Gamma_d * pow(Ice, 4.0) * pow(Gradient, 2.0)\n",
    "Utotal  = Uslide + Udeform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "ax = fig.add_subplot(231)\n",
    "ax.imshow(Gradient, cmap='gray')\n",
    "ax = fig.add_subplot(232)\n",
    "ax.imshow(IceSlopeAngle, cmap='gray')\n",
    "ax = fig.add_subplot(233)\n",
    "ax.imshow(linearstep(Tau, 0, 150000))\n",
    "ax = fig.add_subplot(234)\n",
    "ax.imshow(IceFlowing)\n",
    "ax = fig.add_subplot(235)\n",
    "ax.imshow(linearstep(Uslide, 0, 500))\n",
    "ax = fig.add_subplot(236)\n",
    "ax.imshow(linearstep(Udeform, 0, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IceNeighbors = np.zeros(mapShape)\n",
    "for n in neighs8idx:\n",
    "    IceNeighbors = IceNeighbors + (Ice[n] > 0).astype(np.int)\n",
    "\n",
    "RockIceBorder = np.logical_and(Ice <= 0, IceNeighbors > 0)\n",
    "ValleyWallDF  = cv2.distanceTransform((Ice > 0).astype(np.uint8), cv2.DIST_L2, cv2.DIST_MASK_PRECISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(outPath + 'valleydist.png', np.flipud(encodeFieldAsRGB(max(dx,dy)*ValleyWallDF).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Glacier segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Upflow segmentation of glacial basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reachable cells downflow from a set of source nodes, returns also distances and source mask\n",
    "def downflowCells(surface, mask, sources):\n",
    "    \n",
    "    downflow = np.full(mask.shape, False)\n",
    "    distance = np.full(mask.shape, 0.0)\n",
    "    isSource = np.full(mask.shape, False)\n",
    "    \n",
    "    Q = queue.PriorityQueue()\n",
    "    for s in sources:\n",
    "        Q.put((0, tuple(s)))\n",
    "        isSource[tuple(s)] = True\n",
    "        \n",
    "    while not Q.empty():\n",
    "        d,p = Q.get()\n",
    "        \n",
    "        if downflow[p]: # already visited\n",
    "            continue\n",
    "    \n",
    "        downflow[p] = True\n",
    "        distance[p] = d\n",
    "        for n,dn in zip(CELL_NEIGHS, DIST_NEIGHS):\n",
    "            pn = (p[0] + n[0], p[1] + n[1])\n",
    "            if 0 <= pn[0] < nx and 0 <= pn[1] < ny:  \n",
    "                if not downflow[pn] and mask[pn] and surface[pn] <= surface[p]:\n",
    "                    Q.put((d+dn, pn))\n",
    "    \n",
    "    return downflow, distance, isSource\n",
    "\n",
    "\n",
    "# reachable cells upflow from a set of source nodes, returns also distances and source mask\n",
    "def upflowCells(surface, mask, sources):\n",
    "    \n",
    "    upflow   = np.full(mask.shape, False)\n",
    "    distance = np.full(mask.shape, 0.0)\n",
    "    isSource = np.full(mask.shape, False)\n",
    "    \n",
    "    Q = queue.PriorityQueue()\n",
    "    for s in sources:\n",
    "        Q.put((0, tuple(s)))\n",
    "        isSource[tuple(s)] = True\n",
    "        \n",
    "    while not Q.empty():\n",
    "        d,p = Q.get()\n",
    "        \n",
    "        if upflow[p]: # already visited\n",
    "            continue\n",
    "    \n",
    "        upflow[p] = True\n",
    "        distance[p] = d\n",
    "        for n,dn in zip(CELL_NEIGHS, DIST_NEIGHS):\n",
    "            pn = (p[0] + n[0], p[1] + n[1])\n",
    "            if 0 <= pn[0] < nx and 0 <= pn[1] < ny:  \n",
    "                if not upflow[pn] and mask[pn] and surface[pn] >= surface[p]:\n",
    "                    Q.put((d+dn, pn))\n",
    "    \n",
    "    return upflow, distance, isSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment all glaciers by propagating upflow from lowest points and keeping those big enough\n",
    "def upflowSegmentation(surface, mask, minGlacierCells):\n",
    "    \n",
    "    GlacierIds = np.zeros(mask.shape, dtype=np.int)\n",
    "    GlacierMin = np.zeros((1,2), dtype=np.int)\n",
    "\n",
    "    remaining = mask.copy()\n",
    "    idGlacier = 1\n",
    "\n",
    "    while remaining.any():\n",
    "\n",
    "        iceIdx = np.where(remaining.flatten())[0]\n",
    "        pmin = np.unravel_index(iceIdx[surface.flatten()[iceIdx].argmin()], surface.shape)\n",
    "        \n",
    "        glacierSeg,_,_ = upflowCells(surface, remaining, [pmin])\n",
    "        remaining[glacierSeg] = False\n",
    "\n",
    "        if (glacierSeg.sum() >= minGlacierCells):\n",
    "            print('Glacier area', idGlacier, glacierSeg.sum()*dx*dy/1e6, 'km2')\n",
    "            GlacierIds[glacierSeg] = idGlacier\n",
    "            GlacierMin = np.vstack([GlacierMin, pmin])\n",
    "            idGlacier += 1\n",
    "    \n",
    "    return GlacierIds, GlacierMin, idGlacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minGlacierArea = 1e6 # 1 km2\n",
    "GlacierIdMap, GlacierMinPoints, numGlaciers = upflowSegmentation(Surf, Ice > 0, minGlacierArea/(dx*dy))\n",
    "print('Found', numGlaciers, 'relevant glacier areas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "_ = plt.figure(figsize=(15,15))\n",
    "plt.imshow(GlacierIdMap, cmap='terrain')\n",
    "plt.plot(GlacierMinPoints[1:,1], GlacierMinPoints[1:,0], 'ro', markersize=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Subglaciers segmentation using skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlacierSkeleton:\n",
    "    \n",
    "    def __init__(self, mask):\n",
    "        \n",
    "        self.mask = mask\n",
    "        self.numPoints = mask.sum()\n",
    "        \n",
    "        self.idMap  = np.full(self.mask.shape, -1)        \n",
    "        self.points = np.zeros((self.numPoints,2), dtype=np.int)\n",
    "        skeletonX, skeletonY = self.mask.nonzero()\n",
    "        for i in range(self.numPoints):\n",
    "            sx = skeletonX[i]\n",
    "            sy = skeletonY[i]\n",
    "            self.points[i] = (sx, sy)\n",
    "            self.idMap[(sx,sy)] = i\n",
    "        \n",
    "        self.property = {}\n",
    "                                \n",
    "    \n",
    "    def avgProperty(self, name, values, smoothingRadius):\n",
    "        \n",
    "        if len(values.shape) > 2:\n",
    "            propVals = np.zeros((self.numPoints, values.shape[2]))\n",
    "        else:            \n",
    "            propVals = np.zeros((self.numPoints, 1))\n",
    "            \n",
    "        smoothingRadiusX = int(np.round(smoothingRadius/dx))\n",
    "        smoothingRadiusY = int(np.round(smoothingRadius/dy))\n",
    "        \n",
    "        for i in range(self.numPoints):\n",
    "            nsum = 0\n",
    "            sx,sy = self.points[i]\n",
    "            for di in range(-smoothingRadiusX, smoothingRadiusX+1):\n",
    "                for dj in range(-smoothingRadiusY, smoothingRadiusY+1):\n",
    "                    px = sx+di\n",
    "                    py = sy+dj\n",
    "                    if self.mask[px, py]:\n",
    "                        propVals[i] += values[px,py]\n",
    "                        nsum += 1\n",
    "            propVals[i] /= nsum\n",
    "        \n",
    "        self.property[name] = propVals\n",
    "\n",
    "        \n",
    "    def assignFlowDirection(self):\n",
    "        \n",
    "        # in order to simplify the graph into a tree, assume each node only flows to another one\n",
    "        self.flowTo  = np.full((self.numPoints, ), -1)\n",
    "        \n",
    "        # the lowest point on the skeleton will be the endpoint, not flowing anywhere\n",
    "        self.minId = self.property['S'].argmin()\n",
    "        minPoint   = self.points[self.minId]\n",
    "        \n",
    "        # we want to compute also how far from the endpoint we are\n",
    "        self.distToMin = np.full((self.numPoints, ), -1.0)\n",
    "                \n",
    "        # dijkstra search, based on some cost\n",
    "        PQ = queue.PriorityQueue()\n",
    "        PQ.put((0, 0, (minPoint[0], minPoint[1]), -1))\n",
    "        while not PQ.empty():\n",
    "            \n",
    "            _,d,p,pfrom = PQ.get()\n",
    "            pid = self.idMap[p]\n",
    "\n",
    "            # if we have already visited this node, skip\n",
    "            if self.flowTo[pid] >= 0:\n",
    "                continue\n",
    "\n",
    "            self.flowTo[pid] = pfrom\n",
    "            self.distToMin[pid] = d\n",
    "            \n",
    "            for i,n in enumerate(CELL_NEIGHS): \n",
    "\n",
    "                pn  = (p[0] + n[0], p[1] + n[1])\n",
    "                nid = self.idMap[pn]\n",
    "                dn  = d + DIST_NEIGHS[i]\n",
    "\n",
    "                # if skeleton neighbor\n",
    "                if self.mask[pn] and nid != self.minId:\n",
    "                    # cost based only on distance\n",
    "                    #PQ.put((dn, dn, pn, pid))   \n",
    "                    # cost based on dist^2 and inversely proportional to stress (to better follow flows)\n",
    "                    PQ.put((dn*dn/self.property['Tau'][nid], dn, pn, pid))  \n",
    "                    \n",
    "        \n",
    "    def findSubflows(self, minSubglacierLength):\n",
    "        \n",
    "        # we want to assign a subglacier id to each skeleton node\n",
    "        self.subglacier = np.zeros((self.numPoints, ), dtype=np.int)\n",
    "        \n",
    "        # keep list of source nodes and where they merge to another glacier\n",
    "        self.subglacierSources = [-1]\n",
    "        self.subglacierUnions  = [-1]\n",
    "        self.subglacierLengths = [0]\n",
    "        \n",
    "        # first, compute how many nodes flow to each one\n",
    "        self.inflows = np.full((self.numPoints,), 0)\n",
    "        for i in range(self.numPoints):\n",
    "            self.inflows[i] = np.sum(self.flowTo == i)\n",
    "           \n",
    "        # sources are nodes with no inflow\n",
    "        sources = (self.inflows == 0).nonzero()[0]\n",
    "        sourceDistToGlacier = self.distToMin[sources]\n",
    "        \n",
    "        subglacierId = 0\n",
    "        \n",
    "        # while not visited sources\n",
    "        while sourceDistToGlacier.max() > minSubglacierLength:\n",
    "                        \n",
    "            # new subglacier\n",
    "            subglacierId += 1\n",
    "                        \n",
    "            # get farthest source\n",
    "            maxId = sourceDistToGlacier.argmax()\n",
    "            farthestSource = sources[maxId]\n",
    "            sourceDistToGlacier[maxId] = 0\n",
    "            \n",
    "            # propagate \"downflow\" until we either reach an endpoint or an already visited subglacier\n",
    "            currNode = farthestSource\n",
    "            while self.flowTo[currNode] >= 0 and self.subglacier[currNode] == 0:\n",
    "                self.subglacier[currNode] = subglacierId\n",
    "                currNode = self.flowTo[currNode]\n",
    "            if self.subglacier[currNode] == 0:\n",
    "                self.subglacier[currNode] = subglacierId\n",
    "                        \n",
    "            # save source and union nodes\n",
    "            self.subglacierSources.append(farthestSource)\n",
    "            self.subglacierUnions .append(currNode)\n",
    "            self.subglacierLengths.append(sourceDistToGlacier.max())\n",
    "                        \n",
    "            # now update all distances for remaining sources\n",
    "            for i in range(sourceDistToGlacier.size):\n",
    "                \n",
    "                sid = sources[i]\n",
    "\n",
    "                # already part of a glacier?\n",
    "                if self.subglacier[sid] > 0:\n",
    "                    continue\n",
    "\n",
    "                # find distance to some already seen glacier\n",
    "                curr = sid\n",
    "                while curr >= 0 and self.subglacier[curr] == 0:\n",
    "                    curr = self.flowTo[curr]\n",
    "                sourceDistToGlacier[i] = self.distToMin[sid] - (self.distToMin[curr] if curr >= 0 else 0)\n",
    "                \n",
    "        self.numSubglaciers = subglacierId    \n",
    "        \n",
    "        \n",
    "    def subflowsMap(self):\n",
    "        smap = np.zeros(self.mask.shape)\n",
    "        for i in range(self.numPoints):\n",
    "            smap[tuple(self.points[i])] = self.subglacier[i]\n",
    "        return smap\n",
    "        \n",
    "    \n",
    "    def downflowPath(self, startNode, endNode):\n",
    "        nodes = []\n",
    "        curr = startNode\n",
    "        while self.flowTo[curr] >= 0 and curr != endNode:\n",
    "            nodes.append(curr)\n",
    "            curr = self.flowTo[curr]\n",
    "        return nodes\n",
    "        \n",
    "    \n",
    "    # find the closest non-skeleton cell that is reachable from both branchA and branchB without intersecting the skeleton\n",
    "    def findClosestInbetweenPoint(self, unionNode, nodeBranchA, nodeBranchB, surface):\n",
    "\n",
    "        pointU = self.points[unionNode]\n",
    "        pointA = self.points[nodeBranchA]\n",
    "        pointB = self.points[nodeBranchB]\n",
    "        \n",
    "        sharedPoint = pointU\n",
    "        minDist = 10\n",
    "        maxSurf = surface[tuple(pointU)]\n",
    "        for di in range(-3,4):\n",
    "            for dj in range(-3,4):                \n",
    "                pn = [pointU[0] + di, pointU[1] + dj]\n",
    "                if self.idMap[tuple(pn)] >= 0:\n",
    "                    continue\n",
    "                distA = np.linalg.norm(pointA - pn)\n",
    "                distB = np.linalg.norm(pointB - pn)\n",
    "                dist = distA + distB\n",
    "                if dist < minDist or (dist == minDist and surface[tuple(pn)] > maxSurf):\n",
    "                    if lineSign(pointA, pointU, pn) * lineSign(pointB, pointU, pn) < 0:\n",
    "                        minDist = dist\n",
    "                        sharedPoint = pn\n",
    "                        maxSurf = surface[tuple(pn)]\n",
    "                        \n",
    "        return sharedPoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closest cell in goalsMap using a BFS from startPoint and a navmap\n",
    "def findClosestPoint(startPoint, navmap, goalsMap, neighSchema=CELL_NEIGHS):\n",
    "\n",
    "    visited = np.full(navmap.shape, False)\n",
    "    PQ = queue.PriorityQueue()\n",
    "    PQ.put((0, startPoint))\n",
    "    \n",
    "    while not PQ.empty():\n",
    "        d,p = PQ.get()\n",
    "        if goalsMap[p]:\n",
    "            return p,d\n",
    "        if visited[p]:\n",
    "            continue            \n",
    "        visited[p] = True\n",
    "        for n in neighSchema:\n",
    "            pn = (p[0] + n[0], p[1] + n[1])\n",
    "            if navmap[pn]:\n",
    "                dn = np.linalg.norm(np.array(pn) - np.array(startPoint))\n",
    "                PQ.put((dn, pn))\n",
    "        \n",
    "    return None, -1\n",
    "\n",
    "\n",
    "# find the cell with minimum valuefield using a BFS from startPoint and a navmap\n",
    "def findLocalMinimum(valuefield, navmap, startPoint):\n",
    "    pcurr = startPoint\n",
    "    dist  = valuefield[startPoint]\n",
    "    while True:\n",
    "        minDist = dist\n",
    "        minNeigh = pcurr\n",
    "        for n in CELL_NEIGHS:\n",
    "            pn = (pcurr[0] + n[0], pcurr[1] + n[1])\n",
    "            if navmap[pn]:               \n",
    "                d = valuefield[pn]\n",
    "                if d < minDist:\n",
    "                    minDist = d\n",
    "                    minNeigh = pn\n",
    "        if minDist < dist:\n",
    "            dist = minDist\n",
    "            pcurr = minNeigh\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return pcurr, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdivides the contour into A and B, and fills the glacier using a BFS starting with cost 0 at the contours\n",
    "def separateSubglaciers(intersectArea, surface, pointA, pointB, weightA, weightB, idA, idB, proportionalContour):\n",
    "    \n",
    "    # output\n",
    "    subflowmap = np.zeros(intersectArea.shape)\n",
    "    \n",
    "    # get contour\n",
    "    _,contours,_ = cv2.findContours(intersectArea.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    sortedContours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    contour = [(x[0][1], x[0][0]) for x in sortedContours[0]]\n",
    "    \n",
    "    # lowest point on contour\n",
    "    contourMin = 0\n",
    "    for i,c in enumerate(contour):\n",
    "        if surface[c] < surface[contour[contourMin]]:\n",
    "            contourMin = i\n",
    "    \n",
    "    # contour on left and right sides of glacier flow\n",
    "    contourClosestA = np.linalg.norm(np.array(contour - pointA), axis=1).argmin()\n",
    "    contourClosestB = np.linalg.norm(np.array(contour - pointB), axis=1).argmin()\n",
    "    nodesRight = []\n",
    "    for i in range(contourMin+1, contourMin + len(contour)):\n",
    "        cid = i%len(contour)\n",
    "        nodesRight.append(contour[cid])  \n",
    "        if cid == contourClosestA:\n",
    "            contourA = nodesRight\n",
    "            break\n",
    "        elif cid == contourClosestB:\n",
    "            contourB = nodesRight\n",
    "            break\n",
    "            \n",
    "    nodesLeft = []\n",
    "    for i in range(contourMin-1, contourMin - len(contour), -1):\n",
    "        cid = (i + len(contour))%len(contour)\n",
    "        nodesLeft.append(contour[cid])\n",
    "        if cid == contourClosestA:\n",
    "            contourA = nodesLeft\n",
    "            break\n",
    "        elif cid == contourClosestB:\n",
    "            contourB = nodesLeft\n",
    "            break\n",
    "            \n",
    "    # contourA and contourB start at glacier endpoint and follow the glacier shape up until the skeleton. \n",
    "    # if proportional, split contours such that the subflow with largest cost dies before reaching endpoint\n",
    "    if weightA > weightB:\n",
    "        num = int((weightB/weightA)*len(contourA)) if proportionalContour else len(contourA)-1\n",
    "        contourA = contourA[len(contourA)-1 : len(contourA)-num-1 : -1]\n",
    "        contourB = contourB[::-1]\n",
    "    else:\n",
    "        num = int((weightA/weightB)*len(contourB)) if proportionalContour else len(contourB)-1\n",
    "        contourA = contourA[::-1]\n",
    "        contourB = contourB[len(contourB)-1 : len(contourB)-num-1 : -1]\n",
    "\n",
    "    # initialize expansion from contours\n",
    "    PQ = queue.PriorityQueue()\n",
    "    for c in contourA:\n",
    "        dA = np.linalg.norm(np.array([(c[0] - pointA[0])*dx, (c[1] - pointA[1])*dy]))\n",
    "        PQ.put((0, tuple(c), idA, weightA))\n",
    "    for c in contourB:\n",
    "        dB = np.linalg.norm(np.array([(c[0] - pointB[0])*dx, (c[1] - pointB[1])*dy]))\n",
    "        PQ.put((0, tuple(c), idB, weightB))\n",
    "        \n",
    "    # each glacier expands from contours to neighbors, using a weighted expansion\n",
    "    while not PQ.empty():\n",
    "        d,p,g,w = PQ.get()\n",
    "        if subflowmap[p] > 0:\n",
    "            continue\n",
    "        subflowmap[p] = g\n",
    "        for n,dn in zip(CELL_NEIGHS, DIST_NEIGHS):\n",
    "            pn = (p[0] + n[0], p[1] + n[1])\n",
    "            if intersectArea[pn] and subflowmap[pn] <= 0:\n",
    "                PQ.put((d + dn*w, pn, g, w))\n",
    "    \n",
    "    return subflowmap, contourA, contourB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSubglaciers(glacierMask, glacierFlowMask, glacierSurface, skeleton, \n",
    "                       maxSubglaciers, minSubflowWidth, proportionalContour):\n",
    "\n",
    "    # output\n",
    "    subglaciersMap = np.full(mapShape, -1)\n",
    "    subglaciersMap[glacierMask] = 0\n",
    "    subglaciersCount = 0\n",
    "    \n",
    "    # debug\n",
    "    debugInfo = []\n",
    "\n",
    "    # which union nodes will create a subflow?\n",
    "    unionsQueue = queue.PriorityQueue()\n",
    "    for ui,unionNode in enumerate(skeleton.subglacierUnions):\n",
    "        \n",
    "        # skip main glacier\n",
    "        if unionNode < 0:\n",
    "            continue\n",
    "        \n",
    "        # merging nodes info\n",
    "        unionPoint = skeleton.points[unionNode]\n",
    "        flowingNodes = [i for i in (skeleton.flowTo == unionNode).nonzero()[0] if i > 0]\n",
    "        flowingGlaciers = skeleton.subglacier[flowingNodes]\n",
    "        \n",
    "        # we are interested in \"flat\" valley glaciers merging\n",
    "        if skeleton.property['Gradient'][unionNode] > 0.5:\n",
    "            continue\n",
    "        \n",
    "        # we need at least two nodes\n",
    "        if len(flowingNodes) < 2: \n",
    "            continue\n",
    "            \n",
    "        # more than two subglaciers? keep two longest\n",
    "        elif len(flowingNodes) > 2:\n",
    "            lengthSort = [(skeleton.subglacierLengths[gid], nid) for nid,gid in zip(flowingNodes,flowingGlaciers)]\n",
    "            lengthSort = sorted(lengthSort)            \n",
    "            flowingNodes    = [lengthSort[-1][1], lengthSort[-2][1]]\n",
    "            flowingGlaciers = skeleton.subglacier[flowingNodes]\n",
    " \n",
    "        # we now have two glaciers, choose shortest (by skeleton construction, smallest id)\n",
    "        glacierA = flowingGlaciers.max()\n",
    "        unionA   = flowingNodes[flowingGlaciers.argmax()]\n",
    "        sourceA  = skeleton.subglacierSources[glacierA]\n",
    "        \n",
    "        # add union to queue based on surface elevation      \n",
    "        unionsQueue.put((float(skeleton.property['S'][unionNode]), unionNode, flowingNodes))\n",
    "                \n",
    "                        \n",
    "    # let's compute subflows\n",
    "    inglacierDF = cv2.distanceTransform(glacierMask.astype(np.uint8), cv2.DIST_L2, cv2.DIST_MASK_PRECISE)\n",
    "    skelSubflowsMap = skeleton.subflowsMap()\n",
    "    currGlacierFlows = [skeleton.subglacier[skeleton.minId]]\n",
    "\n",
    "    while not unionsQueue.empty() and subglaciersCount < maxSubglaciers:\n",
    "\n",
    "        _,unionNode,flowingNodes = unionsQueue.get()\n",
    "        flowingGlaciers = skeleton.subglacier[flowingNodes]\n",
    "        unionPoint = skeleton.points[unionNode]\n",
    "\n",
    "         # lower ids are longer glaciers, take it as main body B with affluent A\n",
    "        glacierA = flowingGlaciers.max()\n",
    "        glacierB = flowingGlaciers.min()\n",
    "        unionA = flowingNodes[flowingGlaciers.argmax()]\n",
    "        unionB = flowingNodes[flowingGlaciers.argmin()]\n",
    "\n",
    "        # sources\n",
    "        sourceA = skeleton.subglacierSources[glacierA]\n",
    "        sourceB = skeleton.subglacierSources[glacierB]\n",
    "\n",
    "        # we will always merge into already processed glaciers\n",
    "        if glacierB in currGlacierFlows:\n",
    "\n",
    "            # get the path of each branch from its source to union\n",
    "            nodesA = skeleton.downflowPath(sourceA, unionNode)\n",
    "            nodesB = skeleton.downflowPath(sourceB, unionNode)\n",
    "\n",
    "            # find the starting point for the rock wall search\n",
    "            pInbetween = skeleton.findClosestInbetweenPoint(unionNode, unionA, unionB, glacierSurface)\n",
    "            rockSearchMap = np.logical_and(skelSubflowsMap != glacierA, skelSubflowsMap != glacierB)\n",
    "            pRock, _ = findClosestPoint(tuple(pInbetween), rockSearchMap, RockIceBorder, CELL_NEIGHS_4)\n",
    "            if not pRock:\n",
    "                print('  Skipping union at node', unionNode, unionPoint)\n",
    "                continue\n",
    "\n",
    "            # skeleton distances\n",
    "            skeldistA = cv2.distanceTransform((skelSubflowsMap != glacierA).astype(np.uint8), \n",
    "                                              cv2.DIST_L2, cv2.DIST_MASK_PRECISE)\n",
    "            skeldistB = cv2.distanceTransform((skelSubflowsMap != glacierB).astype(np.uint8), \n",
    "                                              cv2.DIST_L2, cv2.DIST_MASK_PRECISE)\n",
    "            skelsdist = np.minimum(skeldistA, skeldistB)\n",
    "\n",
    "            # find closest rock points to each skeleton A and skeleton B\n",
    "            prockA, _ = findLocalMinimum(skeldistA, RockIceBorder, pRock)\n",
    "            prockB, _ = findLocalMinimum(skeldistB, RockIceBorder, pRock)\n",
    "\n",
    "            # find closest skeleton point from each rock\n",
    "            drocksSkelA = np.linalg.norm(skeleton.points[nodesA] - prockA, axis=1)\n",
    "            idxskelA    = drocksSkelA.argmin()\n",
    "            pskelA      = skeleton.points[nodesA[idxskelA]]\n",
    "\n",
    "            drocksSkelB = np.linalg.norm(skeleton.points[nodesB] - prockB, axis=1)\n",
    "            idxskelB    = drocksSkelB.argmin()\n",
    "            pskelB      = skeleton.points[nodesB[idxskelB]]\n",
    "\n",
    "            # refine closest skeleton point upflow until we find a width minima (as approximated by DF)\n",
    "            while idxskelA > 0 and inglacierDF[tuple(skeleton.points[nodesA[idxskelA-1]])] <= \\\n",
    "                                   inglacierDF[tuple(skeleton.points[nodesA[idxskelA]])]:\n",
    "                idxskelA -= 1\n",
    "            while idxskelB > 0 and inglacierDF[tuple(skeleton.points[nodesB[idxskelB-1]])] <= \\\n",
    "                                   inglacierDF[tuple(skeleton.points[nodesB[idxskelB]])]:\n",
    "                idxskelB -= 1\n",
    "            pskelA = skeleton.points[nodesA[idxskelA]]\n",
    "            pskelB = skeleton.points[nodesB[idxskelB]]\n",
    "            \n",
    "            flowWidthA = skeleton.property['ValleyWidth'][nodesA[idxskelA]]#drocksSkelA.min()            \n",
    "            flowWidthB = skeleton.property['ValleyWidth'][nodesB[idxskelB]]#drocksSkelB.min()\n",
    "            \n",
    "            # skip if very small union\n",
    "            if np.minimum(flowWidthA, flowWidthB)*dx < minSubflowWidth:\n",
    "                continue\n",
    "\n",
    "            # find each subglacier mask\n",
    "            maskAvailable = np.logical_or(subglaciersMap == 0, subglaciersMap == glacierB)\n",
    "            maskA, _, _ = downflowCells(glacierSurface, maskAvailable, skeleton.points[nodesA[idxskelA:]])\n",
    "            maskB, _, _ = downflowCells(glacierSurface, maskAvailable, skeleton.points[nodesB[idxskelB:]])\n",
    "\n",
    "            # area we are interested in separating\n",
    "            maskUnion     = np.logical_or(maskA, maskB)\n",
    "            maskIntersect = np.logical_and(maskA, maskB)\n",
    "\n",
    "            # assign weight to each glacier proportional to valley width at this point\n",
    "            wA = 1.0/flowWidthA\n",
    "            wB = 1.0/flowWidthB\n",
    "            \n",
    "\n",
    "            # separate subglaciers\n",
    "            try:\n",
    "                separatedFlows, contourA, contourB = separateSubglaciers(maskUnion, glacierSurface, pskelA, pskelB, \n",
    "                                                                         wA, wB, glacierA, glacierB, proportionalContour)\n",
    "            except Exception as e:\n",
    "                print('  Failed at', unionNode)\n",
    "                print('  ', e)\n",
    "                continue\n",
    "\n",
    "            # cells of a glacier: the ones from the intersection and the ones outside the intersection\n",
    "            subglacierA = np.logical_and(maskA, np.logical_not(maskIntersect))\n",
    "            subglacierA = np.logical_or(subglacierA, separatedFlows == glacierA)\n",
    "            subglacierB = np.logical_and(maskB, np.logical_not(maskIntersect))\n",
    "            subglacierB = np.logical_or(subglacierB, separatedFlows == glacierB)\n",
    "\n",
    "            # update map\n",
    "            subglaciersMap[subglacierA] = glacierA\n",
    "            subglaciersMap[subglacierB] = glacierB\n",
    "            subglaciersCount += 1\n",
    "\n",
    "            # add glacier A as a new potential receiver of tributaries\n",
    "            currGlacierFlows.append(glacierA)\n",
    "\n",
    "            # debug\n",
    "            debugInfo.append({\n",
    "                'nodesA': nodesA,\n",
    "                'nodesB': nodesB,\n",
    "                'maskA': maskA,\n",
    "                'maskB': maskB,\n",
    "                'glacierA': glacierA,\n",
    "                'glacierB': glacierB,\n",
    "                'separatedFlows': separatedFlows,\n",
    "                'rockSearchMap': rockSearchMap,\n",
    "                'intersect': maskIntersect,\n",
    "                'union': maskUnion,\n",
    "                'pUnion': unionPoint,\n",
    "                'pInbetween': pInbetween,\n",
    "                'pRock': pRock,\n",
    "                'prockA': prockA,\n",
    "                'prockB': prockB,\n",
    "                'pskelA': pskelA,\n",
    "                'pskelB': pskelB,\n",
    "                'wA': wA,\n",
    "                'wB': wB,\n",
    "                'contourA': contourA,\n",
    "                'contourB': contourB\n",
    "            })\n",
    "    \n",
    "    # propagate to extend segmented glacier flows\n",
    "    # important to do this at the end, otherwise we interfere with proper subflows segmentation\n",
    "    subflowIds = np.unique(subglaciersMap)\n",
    "    freeNodes = np.logical_and(subglaciersMap == 0, glacierFlowMask)    \n",
    "\n",
    "    PQ = queue.PriorityQueue()\n",
    "    for i in range(skeleton.numPoints):\n",
    "        p = tuple(skeleton.points[i])\n",
    "        g = skeleton.subglacier[i]\n",
    "        if freeNodes[p] and g > 0 and g in subflowIds:\n",
    "            PQ.put((0, p, g))                \n",
    "    while not PQ.empty():\n",
    "        d,p,g = PQ.get()\n",
    "        if not freeNodes[p]:\n",
    "            continue\n",
    "        freeNodes[p] = False\n",
    "        subglaciersMap[p] = g\n",
    "        for n,dn in zip(CELL_NEIGHS, DIST_NEIGHS):\n",
    "            pn = (p[0] + n[0], p[1] + n[1])\n",
    "            if freeNodes[pn] and glacierSurface[pn] < glacierSurface[p] + 1:\n",
    "                PQ.put((d+dn, pn, g))\n",
    "\n",
    "                \n",
    "    return subglaciersMap, debugInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add first empty node to match indices\n",
    "glaciersSubflowMaps = [None]\n",
    "debugInfos = [None]\n",
    "glacierSkeletons = [None]\n",
    "\n",
    "for gid in range(1, numGlaciers):\n",
    "    \n",
    "    # masks of this glacier\n",
    "    g_mask     = GlacierIdMap == gid\n",
    "    g_minPoint = GlacierMinPoints[gid,:]\n",
    "    g_flowing  = np.logical_and(g_mask, Tau > 50000)\n",
    "    g_belowELA = np.logical_and(g_mask, ice_below_ELA)\n",
    "    \n",
    "    # skeletonize\n",
    "    g_skeletonMask = skeletonize(np.logical_or(g_flowing, g_belowELA))\n",
    "    \n",
    "    # compute skeleton information and convert it into a tree (assign a unique outflow cell to each node)\n",
    "    g_skeleton = GlacierSkeleton(g_skeletonMask)\n",
    "    g_skeleton.avgProperty('S', Surf, 100.0)\n",
    "    g_skeleton.avgProperty('Tau', Tau, 100.0)\n",
    "    g_skeleton.avgProperty('Gradient', Gradient, 100.0)\n",
    "    g_skeleton.avgProperty('ValleyWidth', ValleyWallDF, 100.0)\n",
    "    g_skeleton.assignFlowDirection()\n",
    "    \n",
    "    # find subglaciers\n",
    "    numMaxTributaries = 10\n",
    "    minTributaryLength = 3000     # aran 3km, ecrins 5km\n",
    "    minTributaryWidth = 80        # m\n",
    "    proportionalContours = False  # if False, all tributaries reach the same endpoint at glacier tongue\n",
    "    \n",
    "    g_skeleton.findSubflows(minTributaryLength)  \n",
    "    subglaciers, debugInfo = computeSubglaciers(g_mask, g_belowELA, Surf, g_skeleton,  \n",
    "                                                numMaxTributaries, minTributaryWidth, proportionalContours)\n",
    "    glaciersSubflowMaps.append(subglaciers)\n",
    "    \n",
    "    # save skeleton for later reuse\n",
    "    debugInfos.append(debugInfo)\n",
    "    glacierSkeletons.append(g_skeleton)\n",
    "    \n",
    "    print('Glacier %d: %d subglaciers' % (gid, np.unique(subglaciers,return_counts=True)[0].size-1))\n",
    "    \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this map contains a unique identifier for each subflow starting from id=2, and id=1 on other ice mass\n",
    "SubflowIdMap = np.zeros(mapShape, dtype=np.int)\n",
    "SubflowIdMap[Ice > 0] = 1\n",
    "idSubflow = 2\n",
    "\n",
    "# this map identifies the subglacier ids within a glacier, repeated ids possible in different basins\n",
    "SubglacierIdMap = np.zeros(mapShape, dtype=np.int)\n",
    "\n",
    "\n",
    "for gid in range(1, numGlaciers):\n",
    "    idSubglacier = 1        \n",
    "    subflowIds = np.unique(glaciersSubflowMaps[gid])\n",
    "    \n",
    "    for s in subflowIds:\n",
    "        if s <= 0:\n",
    "            continue\n",
    "            \n",
    "        SubflowIdMap[glaciersSubflowMaps[gid] == s] = idSubflow   \n",
    "        idSubflow += 1\n",
    "        \n",
    "        SubglacierIdMap[glaciersSubflowMaps[gid] == s] = idSubglacier\n",
    "        idSubglacier += 1        \n",
    "                \n",
    "numGlacierSubflows = idSubflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(15,15))\n",
    "plt.imshow(SubglacierIdMap + (Ice > 0) + (ice_below_ELA), cmap='terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "OutAreasMap = np.zeros((mapShape[0], mapShape[1], 3), dtype=np.uint8)\n",
    "OutAreasMap[:,:,0] = GlacierIdMap.astype(np.uint8)\n",
    "OutAreasMap[:,:,1] = SubglacierIdMap.astype(np.uint8)\n",
    "\n",
    "cv2.imwrite(outPath + 'segmentation.png', np.flipud(OutAreasMap))  # note OpenCV uses BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug code left here as it might help understand the tributary flows segmentation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugGlacierId = 1\n",
    "\n",
    "d_subglaciers = glaciersSubflowMaps[debugGlacierId]\n",
    "\n",
    "i, j = np.where(d_subglaciers >= 0)\n",
    "bmini = i.min()-1\n",
    "bmaxi = i.max()+1\n",
    "bminj = j.min()-1\n",
    "bmaxj = j.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glacier skeleton\n",
    "d_skel = glacierSkeletons[debugGlacierId]\n",
    "\n",
    "skelmap = np.zeros(mapShape)\n",
    "for i in range(d_skel.numPoints):\n",
    "    skelmap[tuple(d_skel.points[i])] = d_skel.subglacier[i]+50 if d_skel.subglacier[i] > 0 else 5\n",
    "skelmap[Ice == 0] = 2\n",
    "\n",
    "_ = plt.figure(figsize=(20,20))\n",
    "plt.imshow(skelmap[bmini:bmaxi, bminj:bmaxj], cmap='terrain')\n",
    "\n",
    "for dinfo in debugInfos[debugGlacierId]:\n",
    "    plt.plot(dinfo['pUnion'][1]-bminj, dinfo['pUnion'][0]-bmini, 'ro', markersize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour segmentation\n",
    "seeOff = 100\n",
    "subflowId = 1\n",
    "\n",
    "debug = debugInfos[debugGlacierId][subflowId]\n",
    "punion = debug['pUnion']\n",
    "pshared = debug['pInbetween']\n",
    "pRock = debug['pRock']\n",
    "prockA = debug['prockA']\n",
    "prockB = debug['prockB']\n",
    "pskelA = debug['pskelA']\n",
    "pskelB = debug['pskelB']\n",
    "nodesA = debug['nodesA']\n",
    "nodesB = debug['nodesB']\n",
    "\n",
    "bmini = pshared[0] - seeOff\n",
    "bmaxi = pshared[0] + seeOff*3\n",
    "bminj = pshared[1] - seeOff - 20\n",
    "bmaxj = pshared[1] + seeOff\n",
    "\n",
    "_ = plt.figure(figsize=(10,10))\n",
    "plt.imshow(debug['separatedFlows'][bmini:bmaxi, bminj:bmaxj] + 1*(Ice[bmini:bmaxi, bminj:bmaxj] > 0), cmap='terrain')\n",
    "\n",
    "for ni in nodesA:\n",
    "    n = d_skel.points[ni]\n",
    "    if bmini <= n[0] < bmaxi and bminj <= n[1] < bmaxj:\n",
    "        plt.plot(n[1] - bminj, n[0] - bmini, 'co', markersize=8)\n",
    "for ni in nodesB:\n",
    "    n = d_skel.points[ni]\n",
    "    if bmini <= n[0] < bmaxi and bminj <= n[1] < bmaxj:\n",
    "        plt.plot(n[1] - bminj, n[0] - bmini, 'bo', markersize=8)\n",
    "        \n",
    "\n",
    "plt.plot(punion[1] - bminj, punion[0] - bmini, 'r^', markersize=10)\n",
    "plt.plot(pshared[1] - bminj, pshared[0] - bmini, 'ro', markersize=12)\n",
    "plt.plot(pRock[1] - bminj, pRock[0] - bmini, 'go', markersize=12)\n",
    "plt.plot(prockA[1] - bminj, prockA[0] - bmini, 'yo', markersize=10)\n",
    "plt.plot(prockB[1] - bminj, prockB[0] - bmini, 'yo', markersize=10)\n",
    "plt.plot(pskelA[1] - bminj, pskelA[0] - bmini, 'mo', markersize=12)\n",
    "plt.plot(pskelB[1] - bminj, pskelB[0] - bmini, 'mo', markersize=12)\n",
    "\n",
    "for c in debug['contourA']:\n",
    "    if bmini <= c[0] < bmaxi and bminj <= c[1] < bmaxj:\n",
    "        plt.plot(c[1] - bminj, c[0] - bmini, 'co', markersize=4)\n",
    "for c in debug['contourB']:    \n",
    "    if bmini <= c[0] < bmaxi and bminj <= c[1] < bmaxj:\n",
    "        plt.plot(c[1] - bminj, c[0] - bmini, 'bo', markersize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Glacier Feature Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seracs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caused by sudden discontinuities in moving ice surface. We will define a discontinuity between a node and its neighbor if the surface of the neighbor is lower than the node's bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BrokenSurfaceNeighs = np.zeros(mapShape, dtype=np.int)\n",
    "for n in neighs8idx:\n",
    "    alignedToFlow = np.einsum('ijk,kij->ij', FlowDir, np.array(n) - np.array(cellIdx)) > 0\n",
    "    discontinuity = np.logical_and(Ice[n] > 0, Bed > Surf[n])\n",
    "    BrokenSurfaceNeighs = BrokenSurfaceNeighs + np.logical_and(discontinuity, alignedToFlow).astype(np.int)\n",
    "BrokenSurfaceNeighs[Ice <= 0] = 0\n",
    "\n",
    "# Seracs: discontinuity + moving ice\n",
    "Seracs = np.minimum(BrokenSurfaceNeighs/4.0, 1.0) * IceFlowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmini = 500\n",
    "bmaxi = 800\n",
    "bminj = 400\n",
    "bmaxj = 700\n",
    "\n",
    "_ = plt.figure(figsize=(10,10))\n",
    "plt.imshow((Seracs*3.0 + (Ice > 0))[bmini:bmaxi,bminj:bmaxj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(outPath + 'seracs.png', np.flipud((Seracs*255).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rimayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appear at the bottom of steep ice walls, at the interface between this steep and frozen stagnant ice and moving body of the glacier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumIcewallNeighs = np.zeros(mapShape, dtype=np.int)\n",
    "NumFlowingNeighs = np.zeros(mapShape, dtype=np.int)\n",
    "NumFlatNeighs    = np.zeros(mapShape, dtype=np.int)\n",
    "NumSteepNeighs   = np.zeros(mapShape, dtype=np.int)\n",
    "\n",
    "flowAngle = np.cos(np.radians(90.0))\n",
    "steepIce  = IceSlopeAngle > np.radians(30.0)\n",
    "flatIce   = np.logical_not(steepIce)\n",
    "\n",
    "for n in neighs8idx:\n",
    "    flowAlignedNeigh = np.einsum('ijk,kij->ij', FlowDir, np.array(n) - np.array(cellIdx)) < flowAngle\n",
    "    \n",
    "    NumIcewallNeighs = NumIcewallNeighs + np.logical_and.reduce([steepIce[n], flowAlignedNeigh]).astype(np.int)    \n",
    "    NumFlowingNeighs = NumFlowingNeighs + np.logical_and(np.logical_not(steepIce[n]), IceFlowing[n]).astype(np.int)\n",
    "    \n",
    "    NumFlatNeighs  = NumFlatNeighs + flatIce[n].astype(np.int)\n",
    "    NumSteepNeighs = NumSteepNeighs + steepIce[n].astype(np.int)\n",
    "\n",
    "Rimayes = np.logical_and.reduce([steepIce,\n",
    "                                 Tau > 30000,\n",
    "                                 Tau < 60000,\n",
    "                                 ice_above_ELA, \n",
    "                                 NumIcewallNeighs >= 3, \n",
    "                                 NumFlatNeighs >= 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bmini = 500\n",
    "bmaxi = 800\n",
    "bminj = 450\n",
    "bmaxj = 750\n",
    "\n",
    "_ = plt.figure(figsize=(10,10))\n",
    "plt.imshow((Rimayes*5.0 + (Ice > 0))[bmini:bmaxi,bminj:bmaxj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(outPath + 'rimayes.png', np.flipud((Rimayes*255).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Icefalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Icefalls form when ice is flowing under high pressure, and at steep angles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the pixel-based segmentation of icefalls, creates individual falls and improves their shape by extending them\n",
    "# to the rock walls, as well as omitting small segmented areas not large enough to be interesting\n",
    "def icefallSegmentation(icefalls, glacierMask, surface, wallDist, minIcefallSize, maxExtendDist):\n",
    "    \n",
    "    FallIds = np.zeros(icefalls.shape, dtype=np.int)\n",
    "    FallIds[icefalls] = -1\n",
    "    idIcefall = 1\n",
    "    \n",
    "    while (FallIds == -1).any():\n",
    "        \n",
    "        # segment icefall and extend toward valley borders if close enough\n",
    "        Q = queue.Queue()\n",
    "        Q.put((0, tuple(np.argwhere(FallIds == -1)[0])))\n",
    "        while not Q.empty():\n",
    "            d,p = Q.get()\n",
    "            if FallIds[p] > 0 or d > maxExtendDist:\n",
    "                continue\n",
    "            FallIds[p] = idIcefall\n",
    "            for n,dn in zip(CELL_NEIGHS, DIST_NEIGHS):\n",
    "                pn = (p[0] + n[0], p[1] + n[1])\n",
    "                if FallIds[pn] < 0:\n",
    "                    Q.put((0,pn))\n",
    "                elif FallIds[pn] == 0:\n",
    "                    if wallDist[pn]*dx <= maxExtendDist and glacierMask[pn] and surface[pn] > surface[p]:\n",
    "                        Q.put((d+dn,pn))\n",
    "                \n",
    "            \n",
    "        # not large enough? do not count this icefall\n",
    "        if np.logical_and(FallIds == idIcefall, icefalls).sum()*dx*dy < minIcefallSize:\n",
    "            FallIds[FallIds == idIcefall] = 0\n",
    "        else:\n",
    "            idIcefall += 1\n",
    "        \n",
    "    return FallIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icefallFlow  = 100000 # Pa\n",
    "icefallAngle = np.radians(15)\n",
    "\n",
    "# icefall locations\n",
    "IcefallCandidates = np.logical_and.reduce([Tau > icefallFlow, IceSlopeAngle > icefallAngle])\n",
    "\n",
    "# clean segmentation\n",
    "minIcefallSize = 0.05e6 # km2\n",
    "maxExtendDist  = 100.0  # m\n",
    "IcefallIds = icefallSegmentation(IcefallCandidates, Ice > 0, Surf, ValleyWallDF, minIcefallSize, maxExtendDist)\n",
    "Icefalls   = IcefallIds > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the comparison before and after cleanup of icefalls\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(Icefalls*5.0 + 1.0*(Ice > 0) + 1.0*ice_below_ELA)\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(IcefallCandidates*5.0 + 1.0*(Ice > 0) + 1.0*ice_below_ELA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(outPath + 'icefalls.png', np.flipud((Icefalls*255).astype(np.uint8)))\n",
    "cv2.imwrite(outPath + 'icefallsRaw.png', np.flipud((IcefallCandidates*255).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ogives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ogives may form at the base of an icefall and generate an ondulation pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowAngle = np.cos(np.radians(45.0))\n",
    "flatAngle = np.radians(15.0)\n",
    "\n",
    "NumIcefallNeighs = np.zeros(mapShape, dtype=np.int)\n",
    "for n in neighs8idx:\n",
    "    flowAligned      = np.einsum('ijk,ijk->ij', FlowDir, FlowDir[n]) > flowAngle\n",
    "    flowFromNeigh    = np.einsum('ijk,kij->ij', FlowDir, np.array(n) - np.array(cellIdx)) < -flowAngle\n",
    "    NumIcefallNeighs = NumIcefallNeighs + np.logical_and.reduce([Icefalls[n], flowAligned, flowFromNeigh]).astype(np.int)\n",
    "\n",
    "OgivesBorder = np.logical_and.reduce([np.logical_not(Icefalls), \n",
    "                                      SubglacierIdMap > 0,\n",
    "                                      IceFlowing,\n",
    "                                      IceSlopeAngle < flatAngle,\n",
    "                                      ice_below_ELA, \n",
    "                                      np.logical_and(NumIcefallNeighs >= 2, NumIcefallNeighs <= 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOgivesMap(icefalls, ogivesBorder, surface, flowDir, subflowsMap):\n",
    "    \n",
    "    # parameters\n",
    "    minOgiveArea  = 0.1e6\n",
    "    minOgiveNodes = 6  # 100m at 20m/pix\n",
    "    maxFlowDev    = np.radians(25)\n",
    "    numSubflows   = subflowsMap.max() + 1\n",
    "    \n",
    "    # result\n",
    "    OgiveMap = np.full(mapShape, -1, dtype=np.int)\n",
    "    OgiveMap[ogivesBorder] = 0\n",
    "    OgiveSources = [[]]\n",
    "    AllSources = []\n",
    "    OgiveDist = np.full(mapShape, -1.0)\n",
    "    \n",
    "    idOgive = 1\n",
    "    while (OgiveMap == 0).any():\n",
    "        \n",
    "        # minimum point\n",
    "        omapIdx = np.where(OgiveMap.flatten() == 0)[0]\n",
    "        pmin = np.unravel_index(omapIdx[surface.flatten()[omapIdx].argmin()], surface.shape)\n",
    "\n",
    "        # 1) find connected ogive source nodes\n",
    "        ogiveNodes = []\n",
    "        sumDprod = 0.0\n",
    "        ogiveSubflow = np.zeros((numSubflows,), dtype=np.int)\n",
    "        Q = queue.Queue()\n",
    "        Q.put((pmin, 0))\n",
    "        while not Q.empty():\n",
    "            p,d = Q.get()\n",
    "            if OgiveMap[p] > 0:\n",
    "                continue\n",
    "            OgiveMap[p] = idOgive\n",
    "            ogiveNodes.append(p)\n",
    "            sumDprod += d\n",
    "            if subflowsMap[p] >= 0:\n",
    "                ogiveSubflow[subflowsMap[p]] += 1\n",
    "            for n,d in zip(CELL_NEIGHS,DIR_NEIGHS):\n",
    "                pn = (p[0] + n[0], p[1] + n[1])\n",
    "                if OgiveMap[pn] == 0:\n",
    "                    dprod = flowDir[pn[0],pn[1],0]*d[0] + flowDir[pn[0],pn[1],1]*d[1]\n",
    "                    Q.put((pn, np.abs(dprod)))\n",
    "                    \n",
    "        AllSources.append(ogiveNodes)          \n",
    "        \n",
    "        # if ogive too small or too unaligned with flow\n",
    "        if len(ogiveNodes) < minOgiveNodes or sumDprod/len(ogiveNodes) > np.cos(0.5*np.pi - maxFlowDev):\n",
    "            OgiveMap[OgiveMap == idOgive] = -1\n",
    "            continue\n",
    "\n",
    "            \n",
    "        # 2) subflows affected by this ogive\n",
    "        flowIds = np.where(ogiveSubflow > 0)[0]\n",
    "        if len(flowIds) == 0:\n",
    "            OgiveMap[OgiveMap == idOgive] = -1\n",
    "            continue\n",
    "\n",
    "            \n",
    "        # 3) downflow from ogive nodes, stopping if another icefall is found\n",
    "        distMap = np.full(OgiveDist.shape, -1.0)\n",
    "        PQ = queue.PriorityQueue()\n",
    "        for n in ogiveNodes:\n",
    "            if subflowsMap[n] in flowIds:\n",
    "                PQ.put((0, n))\n",
    "        while not PQ.empty():\n",
    "            d,p = PQ.get()\n",
    "            if distMap[p] >= 0:\n",
    "                continue                \n",
    "            distMap[p] = d\n",
    "            for n,dn in zip(CELL_NEIGHS, DIST_NEIGHS):\n",
    "                pn = (p[0] + n[0], p[1] + n[1])\n",
    "                if subflowsMap[pn] in flowIds and not icefalls[pn] and distMap[pn] < 0 and surface[pn] <= surface[p]:\n",
    "                    PQ.put((d+dn, pn))\n",
    "                    \n",
    "        # filter out small sections\n",
    "        for fid in flowIds:\n",
    "            fidOgive = np.logical_and(subflowsMap == fid, distMap >= 0)\n",
    "            if fidOgive.sum()*dx*dy < minOgiveArea:\n",
    "                distMap[fidOgive] = -1\n",
    "        \n",
    "        if (distMap >= 0).sum()*dx*dy < minOgiveArea:\n",
    "            OgiveMap[OgiveMap == idOgive] = -1\n",
    "            continue\n",
    "                    \n",
    "                    \n",
    "        # copy result\n",
    "        OgiveMap [distMap >= 0] = idOgive\n",
    "        OgiveDist[distMap >= 0] = distMap[distMap >= 0]\n",
    "        OgiveSources.append(ogiveNodes)\n",
    "\n",
    "        # go for the next one\n",
    "        idOgive += 1\n",
    "    \n",
    "    \n",
    "    return OgiveMap, OgiveDist, OgiveSources, AllSources\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OgivesMap, OgivesDist, OgivesSources, AllSources = createOgivesMap(Icefalls, OgivesBorder, Surf, FlowDir, SubflowIdMap)\n",
    "\n",
    "print('Found %d ogive areas'%OgivesMap.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OgivesCtrDist = np.zeros(OgivesMap.shape)\n",
    "for i in range(1, OgivesMap.max()+1):\n",
    "    ogiveSkeletonMask = np.logical_not(skeletonize(OgivesMap == i))\n",
    "    dist = cv2.distanceTransform(ogiveSkeletonMask.astype(np.uint8), cv2.DIST_L2, cv2.DIST_MASK_PRECISE)\n",
    "    dist[OgivesMap != i] = 0\n",
    "    OgivesCtrDist += dist\n",
    "OgivesCtrDist *= np.maximum(dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmini = 550\n",
    "bmaxi = 850\n",
    "bminj = 250\n",
    "bmaxj = 550\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow((OgivesMap + 300*(OgivesMap > 0) + 3.0*SubglacierIdMap + 100*Icefalls)[bmini:bmaxi,bminj:bmaxj], cmap='terrain')\n",
    "for os in AllSources:\n",
    "    for s in os:\n",
    "        if bmini <= s[0] <= bmaxi and bminj <= s[1] <= bmaxj:\n",
    "            ax.plot(s[1]-bminj, s[0]-bmini, 'mo', markersize=3)\n",
    "for os in OgivesSources:\n",
    "    for s in os:\n",
    "        if bmini <= s[0] <= bmaxi and bminj <= s[1] <= bmaxj:\n",
    "            ax.plot(s[1]-bminj, s[0]-bmini, 'ro', markersize=4)\n",
    "            \n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(np.cos((OgivesDist + OgivesCtrDist)/30.0)[bmini:bmaxi,bminj:bmaxj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(outPath + 'ogivesId.png', np.flipud(np.maximum(0, OgivesMap)).astype(np.uint8))\n",
    "cv2.imwrite(outPath + 'ogivesDistSrc.png', np.flipud(encodeFieldAsRGB(OgivesDist).astype(np.uint8)))\n",
    "cv2.imwrite(outPath + 'ogivesDistCtr.png', np.flipud(encodeFieldAsRGB(OgivesCtrDist).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crevasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crevasses appear due to sudden steep changes in glacier slope, different velocities, irregularities on the bedrock or the valley widening/narrowing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's compute some properties that will be useful to place crevasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient of bedrock in the direction of flow\n",
    "Dflow_bed = (FlowDir[:,:,0]*Grad_B_x + FlowDir[:,:,1]*Grad_B_y)*(Ice > 0)\n",
    "\n",
    "# derivative of stress in perpendicular direction to flow\n",
    "Grad_tau_x, Grad_tau_y = gradient(Tau)\n",
    "Dperp_tau = (FlowDir[:,:,1]*Grad_tau_x - FlowDir[:,:,0]*Grad_tau_y)*(ValleyWallDF > 1)\n",
    "\n",
    "# speed derivatives along flow and perpendicular to flow\n",
    "Grad_u_x, Grad_u_y = gradient(Utotal)\n",
    "Dflow_speed = (FlowDir[:,:,0]*Grad_u_x + FlowDir[:,:,1]*Grad_u_y)*(ValleyWallDF > 1)\n",
    "Dperp_speed = (FlowDir[:,:,1]*Grad_u_x - FlowDir[:,:,0]*Grad_u_y)*(ValleyWallDF > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance from the glacier terminus will be used to determine some crevasse types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance map to end of glaciers\n",
    "GlacierEndDist = np.full(mapShape, -1)\n",
    "GlacierMaxDist = np.full(mapShape, -1)\n",
    "for i in range(1, numGlaciers):\n",
    "    print('Computing distmap of glacier %d'%i, end='\\r')\n",
    "    gmask = GlacierIdMap == i\n",
    "    _,gdist,_ = upflowCells(Surf, gmask, [(GlacierMinPoints[i,0], GlacierMinPoints[i,1])])\n",
    "    GlacierEndDist[gmask] = gdist[gmask]\n",
    "    GlacierMaxDist[gmask] = gdist[gmask].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute the width of the glacier over its surface. To do so, we will use the value at the glacier skeleton as extracted from the distance field, and propagate it to each skeleton node closest cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_valleyW = np.zeros(mapShape)\n",
    "\n",
    "for gid in range(1, numGlaciers):\n",
    "    print('Computing valley width of glacier %d'%gid, end='\\r')\n",
    "    \n",
    "    # mask and skeleton\n",
    "    gmask = GlacierIdMap == gid\n",
    "    skel = glacierSkeletons[gid]\n",
    "\n",
    "    # closest skeleton node map\n",
    "    skelNodeMap = np.full(mapShape, -1)\n",
    "    PQ = queue.PriorityQueue()\n",
    "    for i in range(skel.numPoints):\n",
    "        if skel.subglacier[i] > 0:\n",
    "            PQ.put((0, (skel.points[i][0], skel.points[i][1]), i))\n",
    "    while not PQ.empty():\n",
    "        d,p,i = PQ.get()\n",
    "        if skelNodeMap[p] >= 0:\n",
    "            continue\n",
    "        skelNodeMap[p] = i\n",
    "        for n,dn in zip(CELL_NEIGHS, DIST_NEIGHS):\n",
    "            pn = (p[0] + n[0], p[1] + n[1])\n",
    "            if gmask[pn] and skelNodeMap[pn] < 0:\n",
    "                PQ.put((d+dn, pn, i))\n",
    "    \n",
    "    # valley width from skeleton\n",
    "    sk_valleyW[gmask] = (skel.property['ValleyWidth'][skelNodeMap].squeeze())[gmask]\n",
    "    \n",
    "    # compute some derivatives along the skeleton\n",
    "    Dskel_valleyW = np.zeros((skel.numPoints,))\n",
    "    for i in range(skel.numPoints):\n",
    "        n = skel.flowTo[i]\n",
    "        d = np.linalg.norm(skel.points[i] - skel.points[n])\n",
    "        if n >= 0:\n",
    "            Dskel_valleyW[i] = (skel.property['ValleyWidth'][n] - skel.property['ValleyWidth'][i])/d\n",
    "                                                                                \n",
    "# some blurring, helps to remove the discontinuities of the skeleton closest node field\n",
    "sk_valleyW = cv2.GaussianBlur(sk_valleyW, (9,9), 0)\n",
    "\n",
    "# set to 0 outside iced areas\n",
    "sk_valleyW[Ice <= 0] = 0\n",
    "\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valley with derivative along flow direction\n",
    "Grad_skValleyW_x, Grad_skValleyW_y = gradient(sk_valleyW)\n",
    "Dflow_skValleyW = (FlowDir[:,:,0]*Grad_skValleyW_x + FlowDir[:,:,1]*Grad_skValleyW_y)*(ValleyWallDF > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(outPath + 'valleywidth.png', np.flipud(encodeFieldAsRGB(max(dx,dy)*sk_valleyW).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MARGINAL CREVASSES** form due to stress on ice close to glacier margins that moves much lower than ice on glacier center.\n",
    "\n",
    "We will place them below ELA, on relatively flat areas and where the stress is lower than deformation threshold (50 kPa).\n",
    "The probability will decrease towards the center of the glacier, and will be proportional to the variation of stress towards the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to find them\n",
    "MarginalCrevasses = np.logical_and.reduce([ice_below_ELA,\n",
    "                                           IceSlopeAngle < np.radians(10),\n",
    "                                           Tau < 70000]).astype(np.float)\n",
    "\n",
    "# intensity\n",
    "MarginalCrevasses = MarginalCrevasses * np.abs(Dperp_tau)\n",
    "MarginalCrevasses = (MarginalCrevasses - MarginalCrevasses.min())/(MarginalCrevasses.max() - MarginalCrevasses.min())\n",
    "MarginalCrevasses = np.sqrt(MarginalCrevasses * (1 - smoothstep(ValleyWallDF, 3, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = np.where(GlacierIdMap == 1)\n",
    "bmini = i.min()-1\n",
    "bmaxi = i.max()+1\n",
    "bminj = j.min()-1\n",
    "bmaxj = j.max()+1\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.imshow(MarginalCrevasses[bmini:bmaxi,bminj:bmaxj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(outPath + 'crevassesMargin.png', np.flipud((MarginalCrevasses*255).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LONGITUDINAL CREVASSES** form when the valley widens or bends, and there is a compressive stress in the flow direction (i.e. speed slows down) and expansive in direction perpendicular to flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressive forces in the direction of flow -> speed slows down\n",
    "loncrev_slowing = smoothstep(Dflow_speed, 0, -1)\n",
    "\n",
    "# expansive forces in direction perpendicular to flow -> longitudinal openings (acceleration perpendicular to flow)\n",
    "loncrev_expanse = smoothstep(np.abs(Dperp_speed), 0, 10)\n",
    "\n",
    "# they are more usual towards the end of a glacier\n",
    "loncrev_closeToEnd = smoothstep(GlacierEndDist/GlacierMaxDist, 0.4, 0.1)\n",
    "\n",
    "# they occur due to valley opening -> Dflow_skValleyW > 0, \n",
    "# we use step from a negative derivative to avoid sharp transitions\n",
    "loncrev_vOpening = smoothstep(Dflow_skValleyW, -0.01, 0)\n",
    "\n",
    "\n",
    "# probability\n",
    "LongitudinalCrevasses = (loncrev_slowing + loncrev_expanse) * loncrev_closeToEnd * loncrev_vOpening * ice_below_ELA\n",
    "LongitudinalCrevasses = (LongitudinalCrevasses - LongitudinalCrevasses.min())/\\\n",
    "                        (LongitudinalCrevasses.max() - LongitudinalCrevasses.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.imshow(LongitudinalCrevasses[bmini:bmaxi, bminj:bmaxj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(outPath + 'crevassesLong.png', np.flipud((LongitudinalCrevasses*255).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSVERSE CREVASSES** are the most common type. They form when the valley steepens and the flow speeds up, due to tensile stresses on the ice. They form across the glacier, and the margin is typically crevasse-free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second order directional derivative of bedrock to detect bumps on the terrain\n",
    "Dflow_bed_gx, Dflow_bed_gy = gradient(Dflow_bed)\n",
    "D2flow_bed = FlowDir[:,:,0]*Dflow_bed_gx + FlowDir[:,:,1]*Dflow_bed_gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ice accelerating: D speed / d flow > 0\n",
    "transcrev_accel = smoothstep(Dflow_speed, 0, 1)\n",
    "\n",
    "# bedrock irregularities\n",
    "transcrev_bedbumps = np.sqrt(smoothstep(D2flow_bed, 0, -0.005))\n",
    "\n",
    "# valley steepens\n",
    "transcrev_steep = linearstep(IceSlopeAngle, np.radians(10), np.radians(30))\n",
    "\n",
    "# distance to margin\n",
    "transcrev_center = smoothstep(ValleyWallDF, 3, 10)\n",
    "\n",
    "# map\n",
    "TransverseCrevasses = np.logical_and.reduce([Tau > 50000,\n",
    "                                             np.logical_not(Icefalls)])\n",
    "TransverseCrevasses = TransverseCrevasses * (transcrev_accel + transcrev_bedbumps + transcrev_steep)/3.0 * transcrev_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10,10))\n",
    "plt.imshow(TransverseCrevasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(outPath + 'crevassesTrans.png', np.flipud((TransverseCrevasses*255).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
